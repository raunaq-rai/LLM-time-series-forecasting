@article{gruver2023language,
  title     = {Large Language Models Are Zero-Shot Time Series Forecasters},
  author    = {Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew Gordon},
  journal   = {arXiv preprint arXiv:2310.07820},
  year      = {2023},
  note      = {NeurIPS 2023},
  url       = {https://doi.org/10.48550/arXiv.2310.07820}
}


@article{hu2021lora,
  title     = {LoRA: Low-Rank Adaptation of Large Language Models},
  author    = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal   = {arXiv preprint arXiv:2106.09685},
  year      = {2021},
  note      = {Draft v2 includes better baselines, experiments on GLUE, and more on adapter latency},
  url       = {https://arxiv.org/abs/2106.09685}
}

@article{qwen2.5,
  title     = {Qwen2.5 Technical Report},
  author    = {Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and Lin, Huan and Yang, Jian and Tu, Jianhong and Zhang, Jianwei and Yang, Jianxin and Yang, Jiaxi and Zhou, Jingren and Lin, Junyang and Dang, Kai and Lu, Keming and Bao, Keqin and Yang, Kexin and Yu, Le and Li, Mei and Xue, Mingfeng and Zhang, Pei and Zhu, Qin and Men, Rui and Lin, Runji and Li, Tianhao and Tang, Tianyi and Xia, Tingyu and Ren, Xingzhang and Ren, Xuancheng and Fan, Yang and Su, Yang and Zhang, Yichang and Wan, Yu and Liu, Yuqiong and Cui, Zeyu and Zhang, Zhenru and Qiu, Zihan},
  journal   = {arXiv preprint arXiv:2412.15115},
  year      = {2024},
  url       = {https://doi.org/10.48550/arXiv.2412.15115},
  note      = {Additional authors not shown}
}

@article{takeuchi2006lotka,
  title={Evolution of predator--prey systems described by a Lotka--Volterra equation under random environment},
  author={Takeuchi, Y. and Du, N.H. and Hieu, N.T. and Sato, K.},
  journal={Journal of Mathematical Analysis and Applications},
  volume={316},
  number={2},
  pages={291--314},
  year={2006},
  publisher={Elsevier},
  url = {https://doi.org/10.1016/j.jmaa.2005.11.009}
}


@article{zhang2019root,
  title     = {Root Mean Square Layer Normalization},
  author    = {Zhang, Biao and Sennrich, Rico},
  journal   = {arXiv preprint arXiv:1910.07467},
  year      = {2019},
  url       = {https://doi.org/10.48550/arXiv.1910.07467},
  note      = {NeurIPS 2019}
}

@article{shazeer2020glu,
  title     = {GLU Variants Improve Transformer},
  author    = {Shazeer, Noam},
  journal   = {arXiv preprint arXiv:2002.05202},
  year      = {2020},
  url       = {https://doi.org/10.48550/arXiv.2002.05202},
}

@article{delcorro2023skipdecode,
  title={SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference},
  author={Del Corro, Luciano and Del Giorno, Allie and Agarwal, Sahaj and Yu, Bin and Awadallah, Ahmed and Mukherjee, Subhabrata},
  journal={arXiv preprint arXiv:2307.02628},
  year={2023},
  url={https://doi.org/10.48550/arXiv.2307.02628}
}

@software{huggingface,
  author       = {Anthony Moi and Nicolas Patry},
  title        = {HuggingFace's Tokenizers},
  year         = {2023},
  version      = {0.13.4},
  date         = {2023-04-05},
  url          = {https://github.com/huggingface/tokenizers},
  note         = {Fast State-of-the-Art Tokenizers optimized for Research and Production.},
  institution  = {HuggingFace},
  commit       = {37372b6},
  keywords     = {Rust, Tokenizer, NLP},
  license      = {Apache-2.0},
  type         = {software}
}
